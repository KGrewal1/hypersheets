{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats\n",
    "\n",
    "> Statistical functions for portfolio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| echo: false\n",
    "from nbdev.showdoc import *\n",
    "from warnings import warn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil, sqrt\n",
    "from scipy.stats import (\n",
    "    norm as norm, linregress as linregress\n",
    ")\n",
    "\n",
    "import hypersheets.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compsum(returns):\n",
    "    \"\"\"Calculates cumulative compounded returns up to each day, for series of daily returns\"\"\"\n",
    "    return returns.add(1).cumprod() -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.030000\n",
       "1    0.040300\n",
       "2    0.092315\n",
       "3    0.081392\n",
       "4    0.048950\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = pd.Series(np.array([0.03, 0.01, 0.05, -0.01, -0.03]))\n",
    "compsum(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def comp(returns):\n",
    "    \"\"\"Calculates total compounded return, for series of daily returns\"\"\"\n",
    "    return returns.add(1).prod() -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048950094500000096"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = pd.Series(np.array([0.03, 0.01, 0.05, -0.01, -0.03]))\n",
    "comp(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# distribution function: need to decide specifics: should this be using standard deviation\n",
    "# def distribution(returns, compounded=True, prepare_returns=True):\n",
    "#     def get_outliers(data):\n",
    "#         # https://datascience.stackexchange.com/a/57199\n",
    "#         Q1 = data.quantile(0.25)\n",
    "#         Q3 = data.quantile(0.75)\n",
    "#         IQR = Q3 - Q1  # IQR is interquartile range.\n",
    "#         filtered = (data >= Q1 - 1.5 * IQR) & (data <= Q3 + 1.5 * IQR)\n",
    "#         return {\n",
    "#             \"values\": data.loc[filtered].tolist(),\n",
    "#             \"outliers\": data.loc[~filtered].tolist(),\n",
    "#         }\n",
    "\n",
    "#     if isinstance(returns, _pd.DataFrame):\n",
    "#         warn(\"Pandas DataFrame was passed (Series expeted). \"\n",
    "#              \"Only first column will be used.\")\n",
    "#         returns = returns.copy()\n",
    "#         returns.columns = map(str.lower, returns.columns)\n",
    "#         if len(returns.columns) > 1 and 'close' in returns.columns:\n",
    "#             returns = returns['close']\n",
    "#         else:\n",
    "#             returns = returns[returns.columns[0]]\n",
    "\n",
    "#     apply_fnc = comp if compounded else _np.sum\n",
    "#     daily = returns.dropna()\n",
    "\n",
    "#     if prepare_returns:\n",
    "#         daily = _utils._prepare_returns(daily)\n",
    "\n",
    "#     return {\n",
    "#         \"Daily\": get_outliers(daily),\n",
    "#         \"Weekly\": get_outliers(daily.resample('W-MON').apply(apply_fnc)),\n",
    "#         \"Monthly\": get_outliers(daily.resample('M').apply(apply_fnc)),\n",
    "#         \"Quarterly\": get_outliers(daily.resample('Q').apply(apply_fnc)),\n",
    "#         \"Yearly\": get_outliers(daily.resample('A').apply(apply_fnc))\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def expected_return(returns, aggregate=None, compounded=True,\n",
    "                    prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Returns the expected geometric return for a given period\n",
    "    by calculating the geometric holding period return\n",
    "    \"\"\"\n",
    "    # if prepare_returns:\n",
    "    #     returns = utils.prepare_returns(returns)\n",
    "    # returns = utils.aggregate_returns(returns, aggregate, compounded)\n",
    "    return np.product(1 + returns) ** (1 / len(returns)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected geometric return is:\n",
    "$$ \\left(\\prod\\limits_{i=1}^{n}(p_{i})\\right)^{(1/n)} -1$$\n",
    "\n",
    "where $p_{i}$ is 1+ the daily return: $p_{i}=\\frac{v_{i}}{v_{i-1}}=1+r_{i}$, where $v_{i}$ and $r_{i}$ are value and return of the asset on day $i$ respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009603773872040255"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = pd.Series(np.array([0.03, 0.01, 0.05, -0.01, -0.03]))\n",
    "expected_return(returns, aggregate=None, compounded=True,\n",
    "                    prepare_returns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def geometric_mean(retruns, aggregate=None, compounded=True):\n",
    "    \"\"\"Shorthand for expected_return()\"\"\"\n",
    "    return expected_return(retruns, aggregate, compounded)\n",
    "\n",
    "\n",
    "def ghpr(retruns, aggregate=None, compounded=True):\n",
    "    \"\"\"Shorthand for expected_return()\"\"\"\n",
    "    return expected_return(retruns, aggregate, compounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def outliers(returns, quantile=.95):\n",
    "    \"\"\"Returns series of outliers: all values greater than the quantile\"\"\"\n",
    "    return returns[returns > returns.quantile(quantile)].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95     96\n",
       "96     97\n",
       "97     98\n",
       "98     99\n",
       "99    100\n",
       "dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = pd.Series(np.arange(1, 101, 1))\n",
    "outliers(returns, quantile=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def remove_outliers(returns, quantile=.95):\n",
    "    \"\"\"Returns series of returns without the outliers on the top end\"\"\"\n",
    "    return returns[returns < returns.quantile(quantile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      3\n",
       "3      4\n",
       "4      5\n",
       "      ..\n",
       "90    91\n",
       "91    92\n",
       "92    93\n",
       "93    94\n",
       "94    95\n",
       "Length: 95, dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = pd.Series(np.arange(1, 101, 1))\n",
    "remove_outliers(returns, quantile=.95) # the range goes from [1,100] to [1,95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def best(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"Returns the best day/month/week/quarter/year's return\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = utils._prepare_returns(returns)\n",
    "    return utils.aggregate_returns(returns, aggregate, compounded).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def worst(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"Returns the worst day/month/week/quarter/year's return\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = utils._prepare_returns(returns)\n",
    "    return utils.aggregate_returns(returns, aggregate, compounded).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def consecutive_wins(returns, aggregate=None, compounded=True,\n",
    "                     prepare_returns=True):\n",
    "    \"\"\"Returns the maximum consecutive wins by day/month/week/quarter/year\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    returns = _utils.aggregate_returns(returns, aggregate, compounded) > 0\n",
    "    return _utils._count_consecutive(returns).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def consecutive_losses(returns, aggregate=None, compounded=True,\n",
    "                       prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Returns the maximum consecutive losses by\n",
    "    day/month/week/quarter/year\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    returns = _utils.aggregate_returns(returns, aggregate, compounded) < 0\n",
    "    return _utils._count_consecutive(returns).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exposure(returns, prepare_returns=True):\n",
    "    \"\"\"Returns the market exposure time (returns != 0)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "\n",
    "    def _exposure(ret):\n",
    "        ex = len(ret[(~_np.isnan(ret)) & (ret != 0)]) / len(ret)\n",
    "        return _ceil(ex * 100) / 100\n",
    "\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        _df = {}\n",
    "        for col in returns.columns:\n",
    "            _df[col] = _exposure(returns[col])\n",
    "        return _pd.Series(_df)\n",
    "    return _exposure(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def win_rate(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"Calculates the win ratio for a period\"\"\"\n",
    "    def _win_rate(series):\n",
    "        try:\n",
    "            return len(series[series > 0]) / len(series[series != 0])\n",
    "        except Exception:\n",
    "            return 0.\n",
    "\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    if aggregate:\n",
    "        returns = _utils.aggregate_returns(returns, aggregate, compounded)\n",
    "\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        _df = {}\n",
    "        for col in returns.columns:\n",
    "            _df[col] = _win_rate(returns[col])\n",
    "\n",
    "        return _pd.Series(_df)\n",
    "\n",
    "    return _win_rate(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def avg_return(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"Calculates the average return/trade return for a period\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    if aggregate:\n",
    "        returns = _utils.aggregate_returns(returns, aggregate, compounded)\n",
    "    return returns[returns != 0].dropna().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def avg_win(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the average winning\n",
    "    return/trade return for a period\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    if aggregate:\n",
    "        returns = _utils.aggregate_returns(returns, aggregate, compounded)\n",
    "    return returns[returns > 0].dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def avg_loss(returns, aggregate=None, compounded=True, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the average low if\n",
    "    return/trade return for a period\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    if aggregate:\n",
    "        returns = _utils.aggregate_returns(returns, aggregate, compounded)\n",
    "    return returns[returns < 0].dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def volatility(returns, periods=252, annualize=True, prepare_returns=True):\n",
    "    \"\"\"Calculates the volatility of returns for a period\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    std = returns.std()\n",
    "    if annualize:\n",
    "        return std * _np.sqrt(periods)\n",
    "\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rolling_volatility(returns, rolling_period=126, periods_per_year=252,\n",
    "                       prepare_returns=True):\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns, rolling_period)\n",
    "\n",
    "    return returns.rolling(rolling_period).std() * _np.sqrt(periods_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def implied_volatility(returns, periods=252, annualize=True):\n",
    "    \"\"\"Calculates the implied volatility of returns for a period\"\"\"\n",
    "    logret = _utils.log_returns(returns)\n",
    "    if annualize:\n",
    "        return logret.rolling(periods).std() * _np.sqrt(periods)\n",
    "    return logret.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def autocorr_penalty(returns, prepare_returns=False):\n",
    "    \"\"\"Metric to account for auto correlation\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        returns = returns[returns.columns[0]]\n",
    "\n",
    "    # returns.to_csv('/Users/ran/Desktop/test.csv')\n",
    "    num = len(returns)\n",
    "    coef = _np.abs(_np.corrcoef(returns[:-1], returns[1:])[0, 1])\n",
    "    corr = [((num - x)/num) * coef ** x for x in range(1, num)]\n",
    "    return _np.sqrt(1 + 2 * _np.sum(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sharpe(returns, rf=0., periods=252, annualize=True, smart=False):\n",
    "    \"\"\"\n",
    "    Calculates the sharpe ratio of access returns\n",
    "    If rf is non-zero, you must specify periods.\n",
    "    In this case, rf is assumed to be expressed in yearly (annualized) terms\n",
    "    Args:\n",
    "        * returns (Series, DataFrame): Input return series\n",
    "        * rf (float): Risk-free rate expressed as a yearly (annualized) return\n",
    "        * periods (int): Freq. of returns (252/365 for daily, 12 for monthly)\n",
    "        * annualize: return annualize sharpe?\n",
    "        * smart: return smart sharpe ratio\n",
    "    \"\"\"\n",
    "    if rf != 0 and periods is None:\n",
    "        raise Exception('Must provide periods if rf != 0')\n",
    "\n",
    "    returns = _utils._prepare_returns(returns, rf, periods)\n",
    "    divisor = returns.std(ddof=1)\n",
    "    if smart:\n",
    "        # penalize sharpe with auto correlation\n",
    "        divisor = divisor * autocorr_penalty(returns)\n",
    "    res = returns.mean() / divisor\n",
    "\n",
    "    if annualize:\n",
    "        return res * _np.sqrt(\n",
    "            1 if periods is None else periods)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def smart_sharpe(returns, rf=0., periods=252, annualize=True):\n",
    "    \"\"\"Sharpe ratio, penalised with autocorrelation penalty\"\"\"\n",
    "    return sharpe(returns, rf, periods, annualize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rolling_sharpe(returns, rf=0., rolling_period=126,\n",
    "                   annualize=True, periods_per_year=252,\n",
    "                   prepare_returns=True):\n",
    "\n",
    "    if rf != 0 and rolling_period is None:\n",
    "        raise Exception('Must provide periods if rf != 0')\n",
    "\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns, rf, rolling_period)\n",
    "\n",
    "    res = returns.rolling(rolling_period).mean() / \\\n",
    "        returns.rolling(rolling_period).std()\n",
    "\n",
    "    if annualize:\n",
    "        res = res * _np.sqrt(\n",
    "            1 if periods_per_year is None else periods_per_year)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sortino(returns, rf=0, periods=252, annualize=True, smart=False):\n",
    "    \"\"\"\n",
    "    Calculates the sortino ratio of access returns\n",
    "    If rf is non-zero, you must specify periods.\n",
    "    In this case, rf is assumed to be expressed in yearly (annualized) terms\n",
    "    Calculation is based on this paper by Red Rock Capital\n",
    "    http://www.redrockcapital.com/Sortino__A__Sharper__Ratio_Red_Rock_Capital.pdf\n",
    "    \"\"\"\n",
    "    if rf != 0 and periods is None:\n",
    "        raise Exception('Must provide periods if rf != 0')\n",
    "\n",
    "    returns = _utils._prepare_returns(returns, rf, periods)\n",
    "\n",
    "    downside = _np.sqrt((returns[returns < 0] ** 2).sum() / len(returns))\n",
    "\n",
    "    if smart:\n",
    "        # penalize sortino with auto correlation\n",
    "        downside = downside * autocorr_penalty(returns)\n",
    "\n",
    "    res = returns.mean() / downside\n",
    "\n",
    "    if annualize:\n",
    "        return res * _np.sqrt(\n",
    "            1 if periods is None else periods)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def smart_sortino(returns, rf=0, periods=252, annualize=True):\n",
    "    return sortino(returns, rf, periods, annualize, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rolling_sortino(returns, rf=0, rolling_period=126, annualize=True,\n",
    "                    periods_per_year=252, **kwargs):\n",
    "    if rf != 0 and rolling_period is None:\n",
    "        raise Exception('Must provide periods if rf != 0')\n",
    "\n",
    "    if kwargs.get(\"prepare_returns\", True):\n",
    "        returns = _utils._prepare_returns(returns, rf, rolling_period)\n",
    "\n",
    "    downside = returns.rolling(rolling_period).apply(\n",
    "        lambda x: (x.values[x.values < 0]**2).sum()) / rolling_period\n",
    "\n",
    "    res = returns.rolling(rolling_period).mean() / _np.sqrt(downside)\n",
    "    if annualize:\n",
    "        res = res * _np.sqrt(\n",
    "            1 if periods_per_year is None else periods_per_year)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# check logic for this\n",
    "def probabilistic_ratio(series, rf=0., base=\"sharpe\", periods=252, annualize=False, smart=False):\n",
    "\n",
    "    if base.lower() == \"sharpe\":\n",
    "        base = sharpe(series, periods=periods, annualize=False, smart=smart)\n",
    "    elif base.lower() == \"sortino\":\n",
    "        base = sortino(series, periods=periods, annualize=False, smart=smart)\n",
    "    elif base.lower() == \"adjusted_sortino\":\n",
    "        base = adjusted_sortino(series, periods=periods,\n",
    "                                annualize=False, smart=smart)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            '`metric` must be either `sharpe`, `sortino`, or `adjusted_sortino`')\n",
    "    skew_no = skew(series, prepare_returns=False)\n",
    "    kurtosis_no = kurtosis(series, prepare_returns=False)\n",
    "\n",
    "    n = len(series)\n",
    "\n",
    "    sigma_sr = _np.sqrt((1 + (0.5 * base ** 2) - (skew_no * base) +\n",
    "                       (((kurtosis_no - 3) / 4) * base ** 2)) / (n - 1))\n",
    "\n",
    "    ratio = (base - rf) / sigma_sr\n",
    "    psr = _norm.cdf(ratio)\n",
    "\n",
    "    if annualize:\n",
    "        return psr * (252 ** 0.5)\n",
    "    return psr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def probabilistic_sharpe_ratio(series, rf=0., periods=252, annualize=False, smart=False):\n",
    "    return probabilistic_ratio(series, rf, base=\"sharpe\", periods=periods,\n",
    "                               annualize=annualize, smart=smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def probabilistic_sortino_ratio(series, rf=0., periods=252, annualize=False, smart=False):\n",
    "    return probabilistic_ratio(series, rf, base=\"sortino\", periods=periods,\n",
    "                               annualize=annualize, smart=smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def probabilistic_adjusted_sortino_ratio(series, rf=0., periods=252, annualize=False, smart=False):\n",
    "    return probabilistic_ratio(series, rf, base=\"adjusted_sortino\", periods=periods,\n",
    "                               annualize=annualize, smart=smart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def treynor_ratio(returns, benchmark, periods=252., rf=0.):\n",
    "    \"\"\"\n",
    "    Calculates the Treynor ratio\n",
    "    Args:\n",
    "        * returns (Series, DataFrame): Input return series\n",
    "        * benchmatk (String, Series, DataFrame): Benchmark to compare beta to\n",
    "        * periods (int): Freq. of returns (252/365 for daily, 12 for monthly)\n",
    "    \"\"\"\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        returns = returns[returns.columns[0]]\n",
    "\n",
    "    beta = greeks(returns, benchmark, periods=periods).to_dict().get('beta', 0)\n",
    "    if beta == 0:\n",
    "        return 0\n",
    "    return (comp(returns) - rf) / beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def omega(returns, rf=0.0, required_return=0.0, periods=252):\n",
    "    \"\"\"\n",
    "    Determines the Omega ratio of a strategy.\n",
    "    See https://en.wikipedia.org/wiki/Omega_ratio for more details.\n",
    "    \"\"\"\n",
    "    if len(returns) < 2:\n",
    "        return _np.nan\n",
    "\n",
    "    if required_return <= -1:\n",
    "        return _np.nan\n",
    "\n",
    "    returns = _utils._prepare_returns(returns, rf, periods)\n",
    "\n",
    "    if periods == 1:\n",
    "        return_threshold = required_return\n",
    "    else:\n",
    "        return_threshold = (1 + required_return) ** (1. / periods) - 1\n",
    "\n",
    "    returns_less_thresh = returns - return_threshold\n",
    "    numer = returns_less_thresh[returns_less_thresh > 0.0].sum().values[0]\n",
    "    denom = -1.0 * \\\n",
    "        returns_less_thresh[returns_less_thresh < 0.0].sum().values[0]\n",
    "\n",
    "    if denom > 0.0:\n",
    "        return numer / denom\n",
    "\n",
    "    return _np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gain_to_pain_ratio(returns, rf=0, resolution=\"D\"):\n",
    "    \"\"\"\n",
    "    Jack Schwager's GPR. See here for more info:\n",
    "    https://archive.is/wip/2rwFW\n",
    "    \"\"\"\n",
    "    returns = _utils._prepare_returns(returns, rf).resample(resolution).sum()\n",
    "    downside = abs(returns[returns < 0].sum())\n",
    "    return returns.sum() / downside\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cagr(returns, rf=0., compounded=True):\n",
    "    \"\"\"\n",
    "    Calculates the communicative annualized growth return\n",
    "    (CAGR%) of access returns\n",
    "    If rf is non-zero, you must specify periods.\n",
    "    In this case, rf is assumed to be expressed in yearly (annualized) terms\n",
    "    \"\"\"\n",
    "    total = _utils._prepare_returns(returns, rf)\n",
    "    if compounded:\n",
    "        total = comp(total)\n",
    "    else:\n",
    "        total = _np.sum(total)\n",
    "\n",
    "    years = (returns.index[-1] - returns.index[0]).days / 365.\n",
    "\n",
    "    res = abs(total + 1.0) ** (1.0 / years) - 1\n",
    "\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        res = _pd.Series(res)\n",
    "        res.index = returns.columns\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rar(returns, rf=0.):\n",
    "    \"\"\"\n",
    "    Calculates the risk-adjusted return of access returns\n",
    "    (CAGR / exposure. takes time into account.)\n",
    "    If rf is non-zero, you must specify periods.\n",
    "    In this case, rf is assumed to be expressed in yearly (annualized) terms\n",
    "    \"\"\"\n",
    "    returns = _utils._prepare_returns(returns, rf)\n",
    "    return cagr(returns) / exposure(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def skew(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates returns' skewness\n",
    "    (the degree of asymmetry of a distribution around its mean)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return returns.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kurtosis(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates returns' kurtosis\n",
    "    (the degree to which a distribution peak compared to a normal distribution)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return returns.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calmar(returns, prepare_returns=True):\n",
    "    \"\"\"Calculates the calmar ratio (CAGR% / MaxDD%)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    cagr_ratio = cagr(returns)\n",
    "    max_dd = max_drawdown(returns)\n",
    "    return cagr_ratio / abs(max_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ulcer_index(returns):\n",
    "    \"\"\"Calculates the ulcer index score (downside risk measurment)\"\"\"\n",
    "    dd = to_drawdown_series(returns)\n",
    "    return _np.sqrt(_np.divide((dd**2).sum(), returns.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ulcer_performance_index(returns, rf=0):\n",
    "    \"\"\"\n",
    "    Calculates the ulcer index score\n",
    "    (downside risk measurment)\n",
    "    \"\"\"\n",
    "    return (comp(returns)-rf) / ulcer_index(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def upi(returns, rf=0):\n",
    "    \"\"\"Shorthand for ulcer_performance_index()\"\"\"\n",
    "    return ulcer_performance_index(returns, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def serenity_index(returns, rf=0):\n",
    "    \"\"\"\n",
    "    Calculates the serenity index score\n",
    "    (https://www.keyquant.com/Download/GetFile?Filename=%5CPublications%5CKeyQuant_WhitePaper_APT_Part1.pdf)\n",
    "    \"\"\"\n",
    "    dd = to_drawdown_series(returns)\n",
    "    pitfall = - cvar(dd) / returns.std()\n",
    "    return (comp(returns)-rf) / (ulcer_index(returns) * pitfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def risk_of_ruin(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the risk of ruin\n",
    "    (the likelihood of losing all one's investment capital)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    wins = win_rate(returns)\n",
    "    return ((1 - wins) / (1 + wins)) ** len(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ror(returns):\n",
    "    \"\"\"Shorthand for risk_of_ruin()\"\"\"\n",
    "    return risk_of_ruin(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def value_at_risk(returns, sigma=1, confidence=0.95, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculats the daily value-at-risk\n",
    "    (variance-covariance calculation with confidence n)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    mu = returns.mean()\n",
    "    sigma *= returns.std()\n",
    "\n",
    "    if confidence > 1:\n",
    "        confidence = confidence/100\n",
    "\n",
    "    return _norm.ppf(1-confidence, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def var(returns, sigma=1, confidence=0.95, prepare_returns=True):\n",
    "    \"\"\"Shorthand for value_at_risk()\"\"\"\n",
    "    return value_at_risk(returns, sigma, confidence, prepare_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def conditional_value_at_risk(returns, sigma=1, confidence=0.95,\n",
    "                              prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculats the conditional daily value-at-risk (aka expected shortfall)\n",
    "    quantifies the amount of tail risk an investment\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    var = value_at_risk(returns, sigma, confidence)\n",
    "    c_var = returns[returns < var].values.mean()\n",
    "    return c_var if ~_np.isnan(c_var) else var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cvar(returns, sigma=1, confidence=0.95, prepare_returns=True):\n",
    "    \"\"\"Shorthand for conditional_value_at_risk()\"\"\"\n",
    "    return conditional_value_at_risk(\n",
    "        returns, sigma, confidence, prepare_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def expected_shortfall(returns, sigma=1, confidence=0.95):\n",
    "    \"\"\"Shorthand for conditional_value_at_risk()\"\"\"\n",
    "    return conditional_value_at_risk(returns, sigma, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def tail_ratio(returns, cutoff=0.95, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Measures the ratio between the right\n",
    "    (95%) and left tail (5%).\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return abs(returns.quantile(cutoff) / returns.quantile(1-cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def payoff_ratio(returns, prepare_returns=True):\n",
    "    \"\"\"Measures the payoff ratio (average win/average loss)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return avg_win(returns) / abs(avg_loss(returns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def win_loss_ratio(returns, prepare_returns=True):\n",
    "    \"\"\"Shorthand for payoff_ratio()\"\"\"\n",
    "    return payoff_ratio(returns, prepare_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def profit_ratio(returns, prepare_returns=True):\n",
    "    \"\"\"Measures the profit ratio (win ratio / loss ratio)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    wins = returns[returns >= 0]\n",
    "    loss = returns[returns < 0]\n",
    "\n",
    "    win_ratio = abs(wins.mean() / wins.count())\n",
    "    loss_ratio = abs(loss.mean() / loss.count())\n",
    "    try:\n",
    "        return win_ratio / loss_ratio\n",
    "    except Exception:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def profit_factor(returns, prepare_returns=True):\n",
    "    \"\"\"Measures the profit ratio (wins/loss)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return abs(returns[returns >= 0].sum() / returns[returns < 0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cpc_index(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Measures the cpc ratio\n",
    "    (profit factor * win % * win loss ratio)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return profit_factor(returns) * win_rate(returns) * \\\n",
    "        win_loss_ratio(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def common_sense_ratio(returns, prepare_returns=True):\n",
    "    \"\"\"Measures the common sense ratio (profit factor * tail ratio)\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return profit_factor(returns) * tail_ratio(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def outlier_win_ratio(returns, quantile=.99, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the outlier winners ratio\n",
    "    99th percentile of returns / mean positive return\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return returns.quantile(quantile).mean() / returns[returns >= 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def outlier_loss_ratio(returns, quantile=.01, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the outlier losers ratio\n",
    "    1st percentile of returns / mean negative return\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return returns.quantile(quantile).mean() / returns[returns < 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def recovery_factor(returns, prepare_returns=True):\n",
    "    \"\"\"Measures how fast the strategy recovers from drawdowns\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    total_returns = comp(returns)\n",
    "    max_dd = max_drawdown(returns)\n",
    "    return total_returns / abs(max_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def risk_return_ratio(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the return / risk ratio\n",
    "    (sharpe ratio without factoring in the risk-free rate)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    return returns.mean() / returns.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (636710413.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\kirpa\\AppData\\Local\\Temp\\ipykernel_28332\\636710413.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    return (prices / prices.expanding(min_periods=0).max()).min() -\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def max_drawdown(prices):\n",
    "    \"\"\"Calculates the maximum drawdown\"\"\"\n",
    "    prices = _utils._prepare_prices(prices)\n",
    "    return (prices / prices.expanding(min_periods=0).max()).min() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_drawdown_series(returns):\n",
    "    \"\"\"Convert returns series to drawdown series\"\"\"\n",
    "    prices = _utils._prepare_prices(returns)\n",
    "    dd = prices / _np.maximum.accumulate(prices) - 1.\n",
    "    return dd.replace([_np.inf, -_np.inf, -0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drawdown_details(drawdown):\n",
    "    \"\"\"\n",
    "    Calculates drawdown details, including start/end/valley dates,\n",
    "    duration, max drawdown and max dd for 99% of the dd period\n",
    "    for every drawdown period\n",
    "    \"\"\"\n",
    "    def _drawdown_details(drawdown):\n",
    "        # mark no drawdown\n",
    "        no_dd = drawdown == 0\n",
    "\n",
    "        # extract dd start dates\n",
    "        starts = ~no_dd & no_dd.shift(1)\n",
    "        starts = list(starts[starts].index)\n",
    "\n",
    "        # extract end dates\n",
    "        ends = no_dd & (~no_dd).shift(1)\n",
    "        ends = list(ends[ends].index)\n",
    "\n",
    "        # no drawdown :)\n",
    "        if not starts:\n",
    "            return _pd.DataFrame(\n",
    "                index=[], columns=('start', 'valley', 'end', 'days',\n",
    "                                   'max drawdown', '99% max drawdown'))\n",
    "\n",
    "        # drawdown series begins in a drawdown\n",
    "        if ends and starts[0] > ends[0]:\n",
    "            starts.insert(0, drawdown.index[0])\n",
    "\n",
    "        # series ends in a drawdown fill with last date\n",
    "        if not ends or starts[-1] > ends[-1]:\n",
    "            ends.append(drawdown.index[-1])\n",
    "\n",
    "        # build dataframe from results\n",
    "        data = []\n",
    "        for i, _ in enumerate(starts):\n",
    "            dd = drawdown[starts[i]:ends[i]]\n",
    "            clean_dd = -remove_outliers(-dd, .99)\n",
    "            data.append((starts[i], dd.idxmin(), ends[i],\n",
    "                         (ends[i] - starts[i]).days,\n",
    "                         dd.min() * 100, clean_dd.min() * 100))\n",
    "\n",
    "        df = _pd.DataFrame(data=data,\n",
    "                           columns=('start', 'valley', 'end', 'days',\n",
    "                                    'max drawdown',\n",
    "                                    '99% max drawdown'))\n",
    "        df['days'] = df['days'].astype(int)\n",
    "        df['max drawdown'] = df['max drawdown'].astype(float)\n",
    "        df['99% max drawdown'] = df['99% max drawdown'].astype(float)\n",
    "\n",
    "        df['start'] = df['start'].dt.strftime('%Y-%m-%d')\n",
    "        df['end'] = df['end'].dt.strftime('%Y-%m-%d')\n",
    "        df['valley'] = df['valley'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        return df\n",
    "\n",
    "    if isinstance(drawdown, _pd.DataFrame):\n",
    "        _dfs = {}\n",
    "        for col in drawdown.columns:\n",
    "            _dfs[col] = _drawdown_details(drawdown[col])\n",
    "        return _pd.concat(_dfs, axis=1)\n",
    "\n",
    "    return _drawdown_details(drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def kelly_criterion(returns, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the recommended maximum amount of capital that\n",
    "    should be allocated to the given strategy, based on the\n",
    "    Kelly Criterion (http://en.wikipedia.org/wiki/Kelly_criterion)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    win_loss_ratio = payoff_ratio(returns)\n",
    "    win_prob = win_rate(returns)\n",
    "    lose_prob = 1 - win_prob\n",
    "\n",
    "    return ((win_loss_ratio * win_prob) - lose_prob) / win_loss_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing against a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def r_squared(returns, benchmark, prepare_returns=True):\n",
    "    \"\"\"Measures the straight line fit of the equity curve\"\"\"\n",
    "    # slope, intercept, r_val, p_val, std_err = _linregress(\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    _, _, r_val, _, _ = _linregress(\n",
    "        returns, _utils._prepare_benchmark(benchmark, returns.index))\n",
    "    return r_val**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def r2(returns, benchmark):\n",
    "    \"\"\"Shorthand for r_squared()\"\"\"\n",
    "    return r_squared(returns, benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def information_ratio(returns, benchmark, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Calculates the information ratio\n",
    "    (basically the risk return ratio of the net profits)\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    diff_rets = returns - _utils._prepare_benchmark(benchmark, returns.index)\n",
    "\n",
    "    return diff_rets.mean() / diff_rets.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def greeks(returns, benchmark, periods=252., prepare_returns=True):\n",
    "    \"\"\"Calculates alpha and beta of the portfolio\"\"\"\n",
    "    # ----------------------------\n",
    "    # data cleanup\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    benchmark = _utils._prepare_benchmark(benchmark, returns.index)\n",
    "    # ----------------------------\n",
    "\n",
    "    # find covariance\n",
    "    matrix = _np.cov(returns, benchmark)\n",
    "    beta = matrix[0, 1] / matrix[1, 1]\n",
    "\n",
    "    # calculates measures now\n",
    "    alpha = returns.mean() - beta * benchmark.mean()\n",
    "    alpha = alpha * periods\n",
    "\n",
    "    return _pd.Series({\n",
    "        \"beta\":  beta,\n",
    "        \"alpha\": alpha,\n",
    "        # \"vol\": _np.sqrt(matrix[0, 0]) * _np.sqrt(periods)\n",
    "    }).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rolling_greeks(returns, benchmark, periods=252, prepare_returns=True):\n",
    "    \"\"\"Calculates rolling alpha and beta of the portfolio\"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    df = _pd.DataFrame(data={\n",
    "        \"returns\": returns,\n",
    "        \"benchmark\": _utils._prepare_benchmark(benchmark, returns.index)\n",
    "    })\n",
    "    df = df.fillna(0)\n",
    "    corr = df.rolling(int(periods)).corr().unstack()['returns']['benchmark']\n",
    "    std = df.rolling(int(periods)).std()\n",
    "    beta = corr * std['returns'] / std['benchmark']\n",
    "\n",
    "    alpha = df['returns'].mean() - beta * df['benchmark'].mean()\n",
    "\n",
    "    # alpha = alpha * periods\n",
    "    return _pd.DataFrame(index=returns.index, data={\n",
    "        \"beta\": beta,\n",
    "        \"alpha\": alpha\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compare(returns, benchmark, aggregate=None, compounded=True,\n",
    "            round_vals=None, prepare_returns=True):\n",
    "    \"\"\"\n",
    "    Compare returns to benchmark on a\n",
    "    day/week/month/quarter/year basis\n",
    "    \"\"\"\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    benchmark = _utils._prepare_benchmark(benchmark, returns.index)\n",
    "\n",
    "    data = _pd.DataFrame(data={\n",
    "        'Benchmark': _utils.aggregate_returns(\n",
    "            benchmark, aggregate, compounded) * 100,\n",
    "        'Returns': _utils.aggregate_returns(\n",
    "            returns, aggregate, compounded) * 100\n",
    "    })\n",
    "\n",
    "    data['Multiplier'] = data['Returns'] / data['Benchmark']\n",
    "    data['Won'] = _np.where(data['Returns'] >= data['Benchmark'], '+', '-')\n",
    "\n",
    "    if round_vals is not None:\n",
    "        return _np.round(data, round_vals)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def monthly_returns(returns, eoy=True, compounded=True, prepare_returns=True):\n",
    "    \"\"\"Calculates monthly returns\"\"\"\n",
    "    if isinstance(returns, _pd.DataFrame):\n",
    "        warn(\"Pandas DataFrame was passed (Series expeted). \"\n",
    "             \"Only first column will be used.\")\n",
    "        returns = returns.copy()\n",
    "        returns.columns = map(str.lower, returns.columns)\n",
    "        if len(returns.columns) > 1 and 'close' in returns.columns:\n",
    "            returns = returns['close']\n",
    "        else:\n",
    "            returns = returns[returns.columns[0]]\n",
    "\n",
    "    if prepare_returns:\n",
    "        returns = _utils._prepare_returns(returns)\n",
    "    original_returns = returns.copy()\n",
    "\n",
    "    returns = _pd.DataFrame(\n",
    "        _utils.group_returns(returns,\n",
    "                             returns.index.strftime('%Y-%m-01'),\n",
    "                             compounded))\n",
    "\n",
    "    returns.columns = ['Returns']\n",
    "    returns.index = _pd.to_datetime(returns.index)\n",
    "\n",
    "    # get returnsframe\n",
    "    returns['Year'] = returns.index.strftime('%Y')\n",
    "    returns['Month'] = returns.index.strftime('%b')\n",
    "\n",
    "    # make pivot table\n",
    "    returns = returns.pivot('Year', 'Month', 'Returns').fillna(0)\n",
    "\n",
    "    # handle missing months\n",
    "    for month in ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']:\n",
    "        if month not in returns.columns:\n",
    "            returns.loc[:, month] = 0\n",
    "\n",
    "    # order columns by month\n",
    "    returns = returns[['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "                       'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']]\n",
    "\n",
    "    if eoy:\n",
    "        returns['eoy'] = _utils.group_returns(\n",
    "            original_returns, \n",
    "            original_returns.index.year, \n",
    "            compounded=compounded).values\n",
    "\n",
    "    returns.columns = map(lambda x: str(x).upper(), returns.columns)\n",
    "    returns.index.name = None\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('packageDev1')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
