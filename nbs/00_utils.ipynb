{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utility functions for portfolio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| echo: false\n",
    "import io\n",
    "import inspect\n",
    "from typing import Union,TypeVar\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import hypersheets.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def mtd(df):\n",
    "    \"\"\"Restrict a dataframe to only month to date\"\"\"\n",
    "    return df[df.index >= dt.datetime.now(\n",
    "    ).strftime('%Y-%m-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def qtd(df):\n",
    "    \"\"\"Restrict a dataframe to only quarter to date (quarters starting in Jan, Apr, Jun, Oct) \"\"\"\n",
    "    return df[df.index >= dt.datetime.now(\n",
    "    ).strftime('%Y-%m-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ytd(df):\n",
    "    \"\"\"Restrict a dataframe to only year to date\"\"\"\n",
    "    return df[df.index >= dt.datetime.now(\n",
    "    ).strftime('%Y-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pandas_date(df, dates):\n",
    "    \"\"\"Filters a dataframe (with date as the index), to its values on specific days\"\"\"\n",
    "    if not isinstance(dates, list):\n",
    "        dates = [dates]\n",
    "    return df[df.index.isin(dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DoB</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-10-15</th>\n",
       "      <td>alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>charlie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name\n",
       "DoB                \n",
       "2005-10-15    alice\n",
       "2001-01-01  charlie"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = pd.DataFrame({\n",
    "    'name': ['alice','bob','charlie','ryan'],\n",
    "    'DoB': ['2005-10-15','2002-09-03','2001-01-01','1999-12-31']\n",
    "})\n",
    "df = df.set_index('DoB')\n",
    "dates = ['2001-01-01','2005-10-15']\n",
    "pandas_date(df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pandas_current_month(df):\n",
    "    \"\"\"an alternative method to mtd. remove?\"\"\"\n",
    "    n = dt.datetime.now()\n",
    "    daterange = pd.date_range(dt.date(n.year, n.month, 1), n)\n",
    "    return df[df.index.isin(daterange)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def multi_shift(df, shift=3):\n",
    "    \"\"\"Get last N rows relative to another row in dataframe of values, with a sorted index\"\"\"\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "    dfs = [df.shift(i) for i in np.arange(shift)]\n",
    "    for ix, dfi in enumerate(dfs[1:]):\n",
    "        dfs[ix + 1].columns = [str(col) for col in dfi.columns + str(ix + 1)]\n",
    "    return pd.concat(dfs, axis = 1, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>value1</th>\n",
       "      <th>value2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-10-15</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-16</th>\n",
       "      <td>15</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-17</th>\n",
       "      <td>13</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-18</th>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-19</th>\n",
       "      <td>12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-10-20</th>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            value  value1  value2\n",
       "Date                             \n",
       "1999-10-15     10     NaN     NaN\n",
       "1999-10-16     15    10.0     NaN\n",
       "1999-10-17     13    15.0    10.0\n",
       "1999-10-18      7    13.0    15.0\n",
       "1999-10-19     12     7.0    13.0\n",
       "1999-10-20      6    12.0     7.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "df = pd.DataFrame({\n",
    "    'value': [10,15,13,7,12,6],\n",
    "    'Date': ['1999-10-15','1999-10-16','1999-10-17','1999-10-18','1999-10-19','1999-10-20']\n",
    "})\n",
    "df = df.set_index('Date')\n",
    "multi_shift(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_excess_returns(returns:Union['~pd.Series', '~pd.DataFrame'], # Returns\n",
    " rf:Union[float, '~pd.Series', '~pd.DataFrame'] , # Risk-Free rate(s)\n",
    " nperiods:int=None # Will convert rf to different frequency using deannualize\n",
    " )->Union['~pd.Series', '~pd.DataFrame']: #Returns - risk free rate\n",
    "    \"\"\"\n",
    "    Calculates excess returns by subtracting\n",
    "    risk-free returns from total returns\n",
    "    \"\"\"\n",
    "    if isinstance(rf, int):\n",
    "        rf = float(rf)\n",
    "\n",
    "    if not isinstance(rf, float):\n",
    "        rf = rf[rf.index.isin(returns.index)]\n",
    "\n",
    "    if nperiods is not None:\n",
    "        # deannualize\n",
    "        rf = np.power(1 + rf, 1. / nperiods) - 1.\n",
    "\n",
    "    return returns - rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_returns(data, rf=0., nperiods=None):\n",
    "    \"\"\"Converts price data into returns + cleanup\"\"\"\n",
    "    data = data.copy()\n",
    "    function = inspect.stack()[1][3]\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            if data[col].dropna().min() >= 0 and data[col].dropna().max() > 1:\n",
    "                data[col] = data[col].pct_change()\n",
    "    elif data.min() >= 0 and data.max() > 1:\n",
    "        data = data.pct_change()\n",
    "\n",
    "    # cleanup data\n",
    "    data = data.replace([np.inf, -np.inf], float('NaN'))\n",
    "\n",
    "    if isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        data = data.fillna(0).replace(\n",
    "            [np.inf, -np.inf], float('NaN'))\n",
    "    unnecessary_function_calls = ['_prepare_benchmark',\n",
    "                                  'cagr',\n",
    "                                  'gain_to_pain_ratio',\n",
    "                                  'rolling_volatility']\n",
    "\n",
    "\n",
    "    if function not in unnecessary_function_calls:\n",
    "        if rf > 0:\n",
    "            return to_excess_returns(data, rf, nperiods)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_returns(prices, rf=0.):\n",
    "    \"\"\"Calculates the simple arithmetic returns of a price series\"\"\"\n",
    "    return prepare_returns(prices, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_prices(returns, base=1e5):\n",
    "    \"\"\"Converts returns series to price data\"\"\"\n",
    "    returns = returns.copy().fillna(0).replace(\n",
    "        [np.inf, -np.inf], float('NaN'))\n",
    "\n",
    "    return base + base * stats.compsum(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# mock returns array\n",
    "data = np.array([0.1, -0.2, 0.25, 0.5, -0.8])\n",
    "returns = pd.Series(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    110.0\n",
       "1     88.0\n",
       "2    110.0\n",
       "3    165.0\n",
       "4     33.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "to_prices(returns, base=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def to_log_returns(returns, rf=0., nperiods=None):\n",
    "    \"\"\"Converts returns series to log returns\"\"\"\n",
    "    returns = prepare_returns(returns, rf, nperiods)\n",
    "    try:\n",
    "        return np.log(returns+1).replace([np.inf, -np.inf], float('NaN'))\n",
    "    except Exception:\n",
    "        return 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log return is defined as $lr_{i}=\\log\\frac{p_{i}}{p_{i-1}}$ where $lr_{i}$ and $p_{i}$ are the log returns and price on day $i$ respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def log_returns(returns, rf=0., nperiods=None):\n",
    "    \"\"\"Shorthand for to_log_returns\"\"\"\n",
    "    return to_log_returns(returns, rf, nperiods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def exponential_stdev(returns, window=30, is_halflife=False):\n",
    "    \"\"\"Returns series representing exponential volatility of returns\"\"\"\n",
    "    returns = prepare_returns(returns)\n",
    "    halflife = window if is_halflife else None\n",
    "    return returns.ewm(com=None, span=window,\n",
    "                       halflife=halflife, min_periods=window).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_prices(ticker, period=\"max\"):\n",
    "    \"\"\"download daily adjusted close prices from yahoo\"\"\"\n",
    "    if isinstance(period, pd.DatetimeIndex):\n",
    "        p = {\"start\": period[0]}\n",
    "    else:\n",
    "        p = {\"period\": period}\n",
    "\n",
    "    return yf.Ticker(ticker).history(**p)['Close']# this is automatically the adjusted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-09-15    388.524017\n",
       "2022-09-16    385.559998\n",
       "2022-09-19    388.549988\n",
       "2022-09-20    384.089996\n",
       "2022-09-21    377.390015\n",
       "2022-09-22    374.220001\n",
       "2022-09-23    367.950012\n",
       "2022-09-26    364.309998\n",
       "2022-09-27    363.380005\n",
       "2022-09-28    370.529999\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "download_prices('SPY',  period=\"5y\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_returns(ticker, period=\"max\"):\n",
    "    \"\"\"download returns from yahoo\"\"\"\n",
    "    if isinstance(period, pd.DatetimeIndex):\n",
    "        p = {\"start\": period[0]}\n",
    "    else:\n",
    "        p = {\"period\": period}\n",
    "\n",
    "    return prepare_returns(yf.Ticker(ticker).history(**p)['Close']) # this is automatically the adjusted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-09-15   -0.011353\n",
       "2022-09-16   -0.007629\n",
       "2022-09-19    0.007755\n",
       "2022-09-20   -0.011479\n",
       "2022-09-21   -0.017444\n",
       "2022-09-22   -0.008400\n",
       "2022-09-23   -0.016755\n",
       "2022-09-26   -0.009893\n",
       "2022-09-27   -0.002553\n",
       "2022-09-28    0.019676\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "download_returns('SPY',  period=\"5y\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_benchmark(benchmark=None, period=\"max\", rf=0.,\n",
    "                       prep_returns=True):\n",
    "    \"\"\"\n",
    "    Fetch benchmark if ticker is provided, and pass through\n",
    "    prepare_returns()\n",
    "    period can be options or (expected) pd.DatetimeIndex range\n",
    "    \"\"\"\n",
    "    if benchmark is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(benchmark, str):\n",
    "        benchmark = download_returns(benchmark)\n",
    "\n",
    "    elif isinstance(benchmark, pd.DataFrame):\n",
    "        benchmark = benchmark[benchmark.columns[0]].copy()\n",
    "\n",
    "    if isinstance(period, pd.DatetimeIndex) \\\n",
    "        and set(period) != set(benchmark.index):\n",
    "\n",
    "        # Adjust Benchmark to Strategy frequency\n",
    "        benchmark_prices = to_prices(benchmark, base=1)\n",
    "        new_index = pd.date_range(start=period[0], end=period[-1], freq='D')\n",
    "        benchmark = benchmark_prices.reindex(new_index, method='bfill') \\\n",
    "            .reindex(period).pct_change().fillna(0)\n",
    "        benchmark = benchmark[benchmark.index.isin(period)]\n",
    "\n",
    "    if prep_returns:\n",
    "        return prepare_returns(benchmark.dropna(), rf=rf)\n",
    "    return benchmark.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-09-15   -0.011353\n",
       "2022-09-16   -0.007629\n",
       "2022-09-19    0.007755\n",
       "2022-09-20   -0.011479\n",
       "2022-09-21   -0.017444\n",
       "2022-09-22   -0.008400\n",
       "2022-09-23   -0.016755\n",
       "2022-09-26   -0.009893\n",
       "2022-09-27   -0.002553\n",
       "2022-09-28    0.019676\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "prepare_benchmark('SPY',  period=\"5y\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def rebase(prices, base=100.):\n",
    "    \"\"\"\n",
    "    Rebase all series to a given intial base.\n",
    "    This makes comparing/plotting different series together easier.\n",
    "    Args:\n",
    "        * prices: Expects a price series/dataframe\n",
    "        * base (number): starting value for all series.\n",
    "    \"\"\"\n",
    "    return prices.dropna() / prices.dropna().iloc[0] * base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2017-09-29    100.000000\n",
       "2017-10-02    100.433870\n",
       "2017-10-03    100.648790\n",
       "2017-10-04    100.768223\n",
       "2017-10-05    101.365275\n",
       "2017-10-06    101.249840\n",
       "2017-10-09    101.082674\n",
       "2017-10-10    101.349338\n",
       "2017-10-11    101.508575\n",
       "2017-10-12    101.357307\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "prices = download_prices('SPY',  period=\"5y\")\n",
    "rebase(prices, 100).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def group_returns(returns, groupby, compounded=True):\n",
    "    \"\"\"Summarize returns\n",
    "    group_returns(df, df.index.year)\n",
    "    group_returns(df, [df.index.year, df.index.month])\n",
    "    \"\"\"\n",
    "    if compounded:\n",
    "        return returns.groupby(groupby).apply(stats.comp)\n",
    "    return returns.groupby(groupby).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date  Date\n",
       "2021  9      -0.012222\n",
       "      10      0.070163\n",
       "      11     -0.008035\n",
       "      12      0.046248\n",
       "2022  1      -0.052741\n",
       "      2      -0.029517\n",
       "      3       0.037590\n",
       "      4      -0.087769\n",
       "      5       0.002257\n",
       "      6      -0.082460\n",
       "      7       0.092087\n",
       "      8      -0.040802\n",
       "      9      -0.058525\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = download_returns('SPY',  period=\"1y\")\n",
    "group_returns(returns, [returns.index.year,returns.index.month])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for year and month, it creates a multicolumns index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def aggregate_returns(returns, period=None, compounded=True):\n",
    "    \"\"\"Aggregates returns based on date periods, and flattens index\"\"\"\n",
    "    if period is None or 'day' in period:\n",
    "        return returns\n",
    "    index = returns.index\n",
    "\n",
    "    if 'month' in period:\n",
    "        return group_returns(returns, index.month, compounded=compounded)\n",
    "\n",
    "    if 'quarter' in period:\n",
    "        return group_returns(returns, index.quarter, compounded=compounded)\n",
    "\n",
    "    if period == \"A\" or any(x in period for x in ['year', 'eoy', 'yoy']):\n",
    "        return group_returns(returns, index.year, compounded=compounded)\n",
    "\n",
    "    if 'week' in period:\n",
    "        return group_returns(returns, index.week, compounded=compounded)\n",
    "\n",
    "    if 'eow' in period or period == \"W\":\n",
    "        grouped = group_returns(returns, [index.year, index.week],\n",
    "                             compounded=compounded)\n",
    "        grouped.index = grouped.index.to_flat_index()\n",
    "        return grouped\n",
    "\n",
    "    if 'eom' in period or period == \"M\":\n",
    "        grouped = group_returns(returns, [index.year, index.month],\n",
    "                             compounded=compounded)\n",
    "        grouped.index = grouped.index.to_flat_index()\n",
    "        return grouped\n",
    "\n",
    "    if 'eoq' in period or period == \"Q\":\n",
    "        grouped = group_returns(returns, [index.year, index.quarterh],\n",
    "                             compounded=compounded)\n",
    "        grouped.index = grouped.index.to_flat_index()\n",
    "        return grouped\n",
    "\n",
    "    if not isinstance(period, str):\n",
    "        return group_returns(returns, period, compounded)\n",
    "\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 9)    -0.012222\n",
       "(2021, 10)    0.070164\n",
       "(2021, 11)   -0.008035\n",
       "(2021, 12)    0.046248\n",
       "(2022, 1)    -0.052741\n",
       "(2022, 2)    -0.029517\n",
       "(2022, 3)     0.037590\n",
       "(2022, 4)    -0.087769\n",
       "(2022, 5)     0.002257\n",
       "(2022, 6)    -0.082460\n",
       "(2022, 7)     0.092087\n",
       "(2022, 8)    -0.040802\n",
       "(2022, 9)    -0.058525\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "returns = download_returns('SPY',  period=\"1y\")\n",
    "aggregate_returns(returns, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def prepare_prices(data, base=1.):\n",
    "    \"\"\"Converts return data into prices + cleanup\"\"\"\n",
    "    data = data.copy()\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            if data[col].dropna().min() <= 0 or data[col].dropna().max() < 1:\n",
    "                data[col] = to_prices(data[col], base)\n",
    "\n",
    "    # is it returns?\n",
    "    # elif data.min() < 0 and data.max() < 1:\n",
    "    elif data.min() < 0 or data.max() < 1:\n",
    "        data = to_prices(data, base)\n",
    "\n",
    "    if isinstance(data, (pd.DataFrame, pd.Series)):\n",
    "        data = data.fillna(0).replace(\n",
    "            [np.inf, -np.inf], float('NaN'))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def round_to_closest(val, res, decimals=None):\n",
    "    \"\"\"Round to closest resolution\"\"\"\n",
    "    if decimals is None and \".\" in str(res):\n",
    "        decimals = len(str(res).split('.')[1])\n",
    "    return round(round(val / res) * res, decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def file_stream():\n",
    "    \"\"\"Returns a file stream\"\"\"\n",
    "    return io.BytesIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _in_notebook(matplotlib_inline=False):\n",
    "    \"\"\"Identify enviroment (notebook, terminal, etc)\"\"\"\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            # Jupyter notebook or qtconsole\n",
    "            if matplotlib_inline:\n",
    "                get_ipython().magic(\"matplotlib inline\")\n",
    "            return True\n",
    "        if shell == 'TerminalInteractiveShell':\n",
    "            # Terminal running IPython\n",
    "            return False\n",
    "        # Other type (?)\n",
    "        return False\n",
    "    except NameError:\n",
    "        # Probably standard Python interpreter\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _count_consecutive(data):\n",
    "    \"\"\"Counts consecutive data (like cumsum() with reset on zeroes)\"\"\"\n",
    "    def _count(data):\n",
    "        return data * (data.groupby(\n",
    "            (data != data.shift(1)).cumsum()).cumcount() + 1)\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for col in data.columns:\n",
    "            data[col] = _count(data[col])\n",
    "        return data\n",
    "    return _count(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _score_str(val):\n",
    "    \"\"\"Returns + sign for positive values and - for negative values (used in plots)\"\"\"\n",
    "    return (\"\" if \"-\" in val else \"+\") + str(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_index(ticker_weights:(dict), #  A python dict with tickers as keys and weights as values\n",
    "rebalance=\"1M\", # Pandas resample interval or None for never\n",
    "period:(str)=\"max\", # time period of the returns to be downloaded\n",
    "returns:Union['pd.Series', 'pd.DataFrame']=None, #Returns: If provided, check if returns for the ticker are in this dataframe, before trying to download from yahoo\n",
    "match_dates:(bool)=False # whether to match dates?\n",
    ")->Union['pd.Series', 'pd.DataFrame']:#Returns for the index\n",
    "    \"\"\"\n",
    "    Makes an index out of the given tickers and weights.\n",
    "    Optionally you can pass a dataframe with the returns.\n",
    "    If returns is not given it try to download them with yfinance\n",
    "    \"\"\"\n",
    "    # Declare a returns variable\n",
    "    index = None\n",
    "    portfolio = {}\n",
    "\n",
    "    # Iterate over weights\n",
    "    for ticker in ticker_weights.keys():\n",
    "        if (returns is None) or (ticker not in returns.columns):\n",
    "            # Download the returns for this ticker, e.g. GOOG\n",
    "            ticker_returns = download_returns(ticker, period)\n",
    "        else:\n",
    "            ticker_returns = returns[ticker]\n",
    "\n",
    "        portfolio[ticker] = ticker_returns\n",
    "\n",
    "    # index members time-series\n",
    "    index = pd.DataFrame(portfolio).dropna()\n",
    "\n",
    "    if match_dates:\n",
    "        index=index[max(index.ne(0).idxmax()):]\n",
    "\n",
    "    # no rebalance?\n",
    "    if rebalance is None:\n",
    "        for ticker, weight in ticker_weights.items():\n",
    "            index[ticker] = weight * index[ticker]\n",
    "        return index.sum(axis=1)\n",
    "\n",
    "    last_day = index.index[-1]\n",
    "\n",
    "    # rebalance marker\n",
    "    rbdf = index.resample(rebalance).first()\n",
    "    rbdf['break'] = rbdf.index.strftime('%s')\n",
    "\n",
    "    # index returns with rebalance markers\n",
    "    index = pd.concat([index, rbdf['break']], axis=1)\n",
    "\n",
    "    # mark first day day\n",
    "    index['first_day'] = pd.isna(index['break']) & ~pd.isna(index['break'].shift(1))\n",
    "    index.loc[index.index[0], 'first_day'] = True\n",
    "\n",
    "    # multiply first day of each rebalance period by the weight\n",
    "    for ticker, weight in ticker_weights.items():\n",
    "        index[ticker] = np.where(\n",
    "            index['first_day'], weight * index[ticker], index[ticker])\n",
    "\n",
    "    # drop first marker\n",
    "    index.drop(columns=['first_day'], inplace=True)\n",
    "\n",
    "    # drop when all are NaN\n",
    "    index.dropna(how=\"all\", inplace=True)\n",
    "    return index[index.index <= last_day].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirpa\\AppData\\Local\\Temp\\ipykernel_40864\\3101533360.py:62: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return index[index.index <= last_day].sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-09-15   -0.028007\n",
       "2022-09-16   -0.013744\n",
       "2022-09-19    0.015542\n",
       "2022-09-20   -0.019450\n",
       "2022-09-21   -0.035350\n",
       "2022-09-22   -0.020708\n",
       "2022-09-23   -0.033036\n",
       "2022-09-26   -0.014031\n",
       "2022-09-27   -0.002152\n",
       "2022-09-28    0.039568\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_index({'SPY':0.5, 'QQQ':0.5}, period = '5y').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def make_portfolio(returns, start_balance=1e5,\n",
    "                   mode=\"comp\", round_to=None):\n",
    "    \"\"\"Calculates compounded value of portfolio\"\"\"\n",
    "    returns = prepare_returns(returns)\n",
    "\n",
    "    if mode.lower() in [\"cumsum\", \"sum\"]:\n",
    "        p1 = start_balance + start_balance * returns.cumsum()\n",
    "    elif mode.lower() in [\"compsum\", \"comp\"]:\n",
    "        p1 = to_prices(returns, start_balance)\n",
    "    else:\n",
    "        # fixed amount every day\n",
    "        comp_rev = (start_balance + start_balance *\n",
    "                    returns.shift(1)).fillna(start_balance) * returns\n",
    "        p1 = start_balance + comp_rev.cumsum()\n",
    "\n",
    "    # add day before with starting balance\n",
    "    p0 = pd.Series(data=start_balance,\n",
    "                    index=p1.index + pd.Timedelta(days=-1))[:1]\n",
    "\n",
    "    portfolio = pd.concat([p0, p1])\n",
    "\n",
    "    if isinstance(returns, pd.DataFrame):\n",
    "        portfolio.loc[:1, :] = start_balance\n",
    "        portfolio.drop(columns=[0], inplace=True)\n",
    "\n",
    "    if round_to:\n",
    "        portfolio = np.round(portfolio, round_to)\n",
    "\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _flatten_dataframe(df, set_index=None):\n",
    "    \"\"\"Dirty method for flattening multi-index dataframe\"\"\"\n",
    "    s_buf = io.StringIO()\n",
    "    df.to_csv(s_buf)\n",
    "    s_buf.seek(0)\n",
    "\n",
    "    df = pd.read_csv(s_buf)\n",
    "    if set_index is not None:\n",
    "        df.set_index(set_index, inplace=True)\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('packageDev1')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
